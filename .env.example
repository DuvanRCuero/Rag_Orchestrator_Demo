# RAG Orchestrator Environment Configuration

# =============================================================================
# API Settings
# =============================================================================
APP_NAME=RAG Orchestrator
API_VERSION=v1
DEBUG=False
ENVIRONMENT=production

# =============================================================================
# OpenAI Configuration
# =============================================================================
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4-1106-preview
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=1000

# =============================================================================
# Embedding Configuration
# =============================================================================
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
EMBEDDING_DEVICE=cpu  # or "cuda" for GPU

# =============================================================================
# Vector Database (Qdrant)
# =============================================================================
VECTOR_DB_TYPE=qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=rag_documents
# QDRANT_API_KEY=  # Optional for Qdrant Cloud

# =============================================================================
# Cache Configuration (NEW)
# =============================================================================
# Cache type: "redis" for distributed caching, "memory" for single-instance
CACHE_TYPE=redis

# Redis connection URL (used when CACHE_TYPE=redis)
REDIS_URL=redis://localhost:6379/0

# Cache TTL values (in seconds)
CACHE_EMBEDDING_TTL=604800     # 7 days - embeddings are expensive to compute
CACHE_QUERY_TTL=3600           # 1 hour - query results may become stale
CACHE_SESSION_TTL=1800         # 30 minutes - session data is short-lived

# Redis connection pool settings
CACHE_MAX_CONNECTIONS=10

# =============================================================================
# Text Processing
# =============================================================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TEXT_SPLITTER=recursive_character

# =============================================================================
# Retrieval Configuration
# =============================================================================
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.7
USE_HYBRID_SEARCH=True
BM25_WEIGHT=0.3
SEMANTIC_WEIGHT=0.7

# =============================================================================
# Memory Configuration
# =============================================================================
MEMORY_TYPE=buffer_window
MEMORY_WINDOW_SIZE=10

# =============================================================================
# LLM Provider Options (Optional)
# =============================================================================
# Anthropic (Claude)
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Local LLM (Ollama)
# OLLAMA_BASE_URL=http://localhost:11434
# LOCAL_MODEL=llama2

# =============================================================================
# Development & Testing
# =============================================================================
# For development/testing without OpenAI
# LLM_PROVIDER=local
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
